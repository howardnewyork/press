---
title: "Test of Press Regression"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
---

This notebook tests PRESS regression on some datasets.  

See https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46141.pdf  for more details

PRESS is a non-parametric regression system that scales at O(N)

# Initialize 

```{r}
library(rstan)
library(ggplot2)
library(dplyr)
library(tidyr)


working_dir = ""  # change this accordingly
data_dir =paste0(working_dir, "data/")
stan_dir =paste0(working_dir, "stan/")



```

# Required Functions

```{r}

#' Create a list of inputs for stan model

press_list = function(J, x, y, prior_sigma = 2, prior_beta=10, tau=1){
  
  x=cbind(1,x)
  p=ncol(x)
  N=nrow(x)

  ans = list(
    N=N,
    J=J,
    p= p,
    x=x,
    y=y,
    prior_sigma = prior_sigma, 
    prior_beta = prior_beta,
    tau = tau
  )
  
  ans
}

extractPar <- function(stanRun, pars= NULL){
  if (is.null(pars)) pars <- unique(stringr::str_match(names(stanRun$par), "[^\\[]*"))
  results <- list()
  
  for (p in 1:length(pars)){
    parName <- pars[p]
    parVal <- stanRun$par[
      grep(pattern = paste0("^",parName, "(\\[|$)"), x = names(stanRun$par))
      ]
    results[[p]] <- parVal
    noMatches <- length(results[[p]])
    if (noMatches >1) {
      m <- stringr::str_match_all(string = names(parVal), pattern = "[0-9]+")
      if (length(m[[1]])>0){
        m <- do.call(rbind,lapply(m, FUN = function(x) as.numeric((x))))
        results[[p]] <- array(parVal, apply(m, MARGIN = 2, max))
      }
    }
  }
  names(results) <- pars
  results
}



```


# Compile Model

```{r, echo=FALSE}
mod_01 = stan_model(file = paste0(stan_dir, "press_01.stan"))
```



# Test Against Toy Univariate Examples in Paper

## Independant input and output

```{r}
N=100
J=1
x=1:N
y=rnorm(N)

stan_list = press_list(J = 1, x = x, y = y)

run_01 = optimizing(object = mod_01, data=stan_list)
mu = extractPar(run_01, "mu")[[1]]

results = data.frame(record = 1:N, y=y, mu = mu)

ggplot(results) + geom_point(aes(record, y)) + geom_line(aes(record, mu)) + 
  labs(title = "Fitting Independent Data")

```


## Step function

```{r}
N=100
J=3
x=1:N / 100
y=rnorm(N, 0) + ifelse(x>.25 & x <.75, 8,0)
#y=rnorm(N, 0.5) + ifelse(x>.5 , 10,0)

stan_list = press_list(J = J, x = x, y = y, prior_sigma = 1, prior_beta = 10)

run_01 = optimizing(object = mod_01, data=stan_list)
#extractPar(run_01)
mu = extractPar(run_01, "mu")[[1]]
W = extractPar(run_01, "W")[[1]]
beta = extractPar(run_01, "beta")[[1]]
y_bar = extractPar(run_01, "y_bar")[[1]]

#beta
#W
results = data.frame(record = 1:N, y=y, mu = mu)
states = data.frame(state=1:J, y_bar = y_bar) 

ggplot(results) + geom_point(aes(record, y)) + geom_line(aes(record, mu)) + 
  labs(title = "Step Function")

ggplot(states) + geom_point(aes(state, y_bar)) +
  labs(title = "States for Step Function")


```


## Step function with two inputs (cheating method)

```{r}
N=1000
J=2
x=1:N / N
y=rnorm(N, 0) + ifelse(x>.25 & x <.75, 8,0)
#y=rnorm(N, 0.5) + ifelse(x>.5 , 10,0)
x= cbind(x, ifelse(x>.25 & x <.75, 1,0))

stan_list = press_list(J = J, x = x, y = y, prior_sigma = 1, prior_beta = 20)

run_01 = optimizing(object = mod_01, data=stan_list)
#extractPar(run_01)
mu = extractPar(run_01, "mu")[[1]]
W = extractPar(run_01, "W")[[1]]
beta = extractPar(run_01, "beta")[[1]]
y_bar = extractPar(run_01, "y_bar")[[1]]

#beta
#W
results = data.frame(record = 1:N, y=y, mu = mu)
states = data.frame(state=1:J, y_bar = y_bar) 

ggplot(results) + geom_point(aes(record, y)) + geom_line(aes(record, mu)) + 
  labs(title = "Step Function")

ggplot(states) + geom_point(aes(state, y_bar)) +
  labs(title = "States for Step Function")


```

## Step function with multiple inputs

```{r}
N=100
J=2
p=20
x=1:N / N
y=rnorm(N, 0) + ifelse(x>.25 & x <.75, 8,0)
#y=rnorm(N, 0.5) + ifelse(x>.5 , 10,0)
min_x = min(x)
max_x = max(x)
step_val = (max_x - min_x) / (p+1)
x=matrix(x, ncol=1)
for (pp in 2:p){
  x=cbind(x, 
          ifelse(x[,1] > step_val *(pp-1), 1, 0)
          )
}

stan_list = press_list(J = J, x = x, y = y, prior_sigma = 1, prior_beta = 20)

run_01 = optimizing(object = mod_01, data=stan_list)
#extractPar(run_01)
mu = extractPar(run_01, "mu")[[1]]
W = extractPar(run_01, "W")[[1]]
beta = extractPar(run_01, "beta")[[1]]
y_bar = extractPar(run_01, "y_bar")[[1]]

results = data.frame(record = 1:N, y=y, mu = mu)
states = data.frame(state=1:J, y_bar = y_bar) 

ggplot(results) + geom_point(aes(record, y)) + geom_line(aes(record, mu)) + 
  labs(title = "Step Function")

ggplot(states) + geom_point(aes(state, y_bar)) +
  labs(title = "States for Step Function")


```


## linear function

```{r}
N=100
J=6
x=1:N 
y=x+ rnorm(N, 0,1) 

stan_list = press_list(J = J, x = x, y = y, prior_beta = 10)

run_01 = optimizing(object = mod_01, data=stan_list, iter=4000)
#extractPar(run_01)
mu = extractPar(run_01, "mu")
W = extractPar(run_01, "W")
beta = extractPar(run_01, "beta")

y_bar = extractPar(run_01, "y_bar")
states = data.frame(state=1:J, y_bar = y_bar) 


results = data.frame(record = 1:N, y=y, mu = mu)

ggplot(results) + geom_point(aes(record, y)) + geom_line(aes(record, mu)) + 
  labs(title = "Linear Function")

ggplot(states) + geom_point(aes(state, y_bar)) +
  labs(title = "States for Linear Function")

```




## Abalone hors d'oeuvres

Data was derived from here:
Training:  http://download.tensorflow.org/data/abalone_train.csv
Test:  http://download.tensorflow.org/data/abalone_test.csv

```{r}

#Training Data
x= read.csv(paste0(data_dir,"abalone_train.csv"), header = F)
y=x[,8]
x[,8]=NULL

#Test Data
x_test= read.csv(paste0(data_dir,"abalone_test.csv"), header = F)
y_test=x_test[,8]
x_test[,8]=NULL

N=nrow(x)
N_test=nrow(x_test)

if(FALSE){
  set.seed(seed = 21111)
  J=10
} else {
  set.seed(seed = 1111)
  J=11
}

stan_list = press_list(J = J, x = x, y = y, prior_beta = 17, prior_sigma = 2)

run_01 = optimizing(object = mod_01, data=stan_list, iter=4000)
#extractPar(run_01)
mu = extractPar(run_01, "mu")[[1]]
W = extractPar(run_01, "W")[[1]]
beta = extractPar(run_01, "beta")[[1]]
sigma = extractPar(run_01, "sigma")[[1]]

y_bar = extractPar(run_01, "y_bar")[[1]]
states = data.frame(state=1:J, y_bar = y_bar) 


softmax = function(x){
  x=as.vector(x)
  e = exp(x) 
  e / sum(e)
}

##  Out of sample Prediction
x_test_1 = as.matrix(cbind(1, x_test))
W_test = matrix(0, N_test, J)
for (n in 1:N_test){
  W_test[n,] = softmax(beta %*% t(x_test_1[n,,drop=F]))
}
mu_test = W_test %*% y_bar

results = data.frame(record = 1:N, y=y, mu = mu)

print("In Sample MSE")
mse = mean((y-mu)^2)
mse

print("Test MSE")
mse_test = mean((y_test-mu_test)^2)
mse_test
mse_test_2 = mean((y_test-round(mu_test,2))^2)
mse_test_2
mse_test_2^.5

print("Test MAD")
mad_test = mean(abs(y_test-mu_test))
mad_test
mad_test_2 = mean(abs(y_test-round(mu_test,0)))
mad_test_2



ggplot(states) + geom_point(aes(state, y_bar)) +
  labs(title = "States for Linear Function")

```

